# -*- coding:utf-8 -*-
"""
éŸ³é¢‘å·¥å…·æ¨¡å—
æä¾›å½•éŸ³å’Œæ’­æ”¾åŠŸèƒ½
"""
import time

import pyaudio
import wave
import pygame
import os


class AudioRecorder:
    """éŸ³é¢‘å½•åˆ¶ç±»"""

    def __init__(self, sample_rate=16000, channels=1, chunk=1024, input_device_index=None):
        """
        åˆå§‹åŒ–å½•éŸ³å™¨
        :param sample_rate: é‡‡æ ·ç‡
        :param channels: å£°é“æ•°
        :param chunk: éŸ³é¢‘å—å¤§å°
        :param input_device_index: è¾“å…¥è®¾å¤‡ID
        """
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk = chunk
        self.format = pyaudio.paInt16
        self.input_device_index = input_device_index
        self._tested_sample_rates = [16000, 44100, 48000, 22050]  # å¸¸è§é‡‡æ ·ç‡
        self.is_recording = False  # å½•éŸ³çŠ¶æ€æ ‡å¿—
        
    def _find_supported_sample_rate(self, audio):
        """æ‰¾åˆ°è®¾å¤‡æ”¯æŒçš„é‡‡æ ·ç‡"""
        for rate in self._tested_sample_rates:
            try:
                # å°è¯•æ‰“å¼€éŸ³é¢‘æµæµ‹è¯•é‡‡æ ·ç‡
                stream = audio.open(
                    format=self.format,
                    channels=self.channels,
                    rate=rate,
                    input=True,
                    input_device_index=self.input_device_index,
                    frames_per_buffer=self.chunk,
                    start=False  # ä¸å¯åŠ¨æµï¼Œåªæµ‹è¯•é…ç½®
                )
                stream.close()
                print(f"  âœ“ è®¾å¤‡æ”¯æŒé‡‡æ ·ç‡: {rate}Hz")
                return rate
            except Exception:
                continue

        # å¦‚æœéƒ½ä¸æ”¯æŒï¼Œå°è¯•ä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡
        print(f"  âš  ä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡: {self.sample_rate}Hz")
        return self.sample_rate

    def record(self, duration, output_file):
        """
        å½•åˆ¶éŸ³é¢‘
        :param duration: å½•åˆ¶æ—¶é•¿ï¼ˆç§’ï¼‰
        :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆ.pcmæˆ–.wavï¼‰
        :return: å½•åˆ¶çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"  å¼€å§‹å½•éŸ³ï¼Œæ—¶é•¿ {duration} ç§’...")

        # åˆå§‹åŒ–PyAudio
        audio = pyaudio.PyAudio()

        try:
            # æ£€æµ‹æ”¯æŒçš„é‡‡æ ·ç‡
            actual_sample_rate = self._find_supported_sample_rate(audio)

            # æ‰“å¼€éŸ³é¢‘æµ
            print(f"  ä½¿ç”¨é‡‡æ ·ç‡: {actual_sample_rate}Hz, è®¾å¤‡ID: {self.input_device_index}")

            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=actual_sample_rate,
                input=True,
                input_device_index=self.input_device_index,  # æŒ‡å®šéº¦å…‹é£è®¾å¤‡
                frames_per_buffer=self.chunk
            )

            frames = []

            # å½•åˆ¶éŸ³é¢‘
            for i in range(0, int(actual_sample_rate / self.chunk * duration)):
                data = stream.read(self.chunk)
                frames.append(data)

                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + 1) / (actual_sample_rate / self.chunk * duration) * 100
                print(f"\rå½•éŸ³ä¸­... {progress:.0f}%", end='', flush=True)

            print("\n å½•éŸ³å®Œæˆï¼")

            # åœæ­¢å½•éŸ³
            stream.stop_stream()
            stream.close()

            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨å®é™…é‡‡æ ·ç‡ï¼‰
            if output_file.endswith('.pcm'):
                # ä¿å­˜ä¸ºPCMæ ¼å¼ï¼ˆç”¨äºè®¯é£ASRï¼‰
                with open(output_file, 'wb') as f:
                    f.write(b''.join(frames))
            elif output_file.endswith('.wav'):
                # ä¿å­˜ä¸ºWAVæ ¼å¼
                with wave.open(output_file, 'wb') as wf:
                    wf.setnchannels(self.channels)
                    wf.setsampwidth(audio.get_sample_size(self.format))
                    wf.setframerate(actual_sample_rate)  # ä½¿ç”¨å®é™…é‡‡æ ·ç‡
                    wf.writeframes(b''.join(frames))
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨.pcmæˆ–.wav")

            print(f" éŸ³é¢‘å·²ä¿å­˜åˆ°ï¼š{output_file}")
            return output_file

        except Exception as e:
            print(f"\n âŒ å½•éŸ³å¤±è´¥: {e}")
            raise
        finally:
            # ç¡®ä¿PyAudioè¢«æ­£ç¡®å…³é—­
            audio.terminate()

    def record_stream(self, duration, frame_callback, output_file=None):
        """
        æµå¼å½•éŸ³ - è¾¹å½•è¾¹å›è°ƒ
        :param duration: å½•åˆ¶æ—¶é•¿ï¼ˆç§’ï¼‰
        :param frame_callback: å›è°ƒå‡½æ•°ï¼Œæ¯å½•åˆ¶ä¸€å¸§å°±è°ƒç”¨ callback(audio_data)
        :param output_file: å¯é€‰ï¼ŒåŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
        :return: å½•åˆ¶çš„æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›äº†output_fileï¼‰
        """
        print(f"ğŸ™ï¸ å¼€å§‹æµå¼å½•éŸ³ï¼Œæ—¶é•¿ {duration} ç§’...")
        
        self.is_recording = True
        frames = []
        
        # åˆå§‹åŒ–PyAudio
        audio = pyaudio.PyAudio()
        
        try:
            # ä½¿ç”¨16kHzé‡‡æ ·ç‡ï¼ˆè®¯é£ASRè¦æ±‚ï¼‰
            actual_sample_rate = 16000
            
            # ä½¿ç”¨1280å­—èŠ‚å—å¤§å°ï¼ˆè®¯é£ASRæ¨èï¼‰
            chunk_size = 1280
            
            print(f"  ä½¿ç”¨é‡‡æ ·ç‡: {actual_sample_rate}Hz, å—å¤§å°: {chunk_size}å­—èŠ‚")
            
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=actual_sample_rate,
                input=True,
                input_device_index=self.input_device_index,
                frames_per_buffer=chunk_size
            )
            
            # è®¡ç®—æ€»å¸§æ•°
            total_frames = int(actual_sample_rate / chunk_size * duration)
            
            # å½•éŸ³å¾ªç¯
            for i in range(total_frames):
                if not self.is_recording:
                    break
                
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = stream.read(chunk_size, exception_on_overflow=False)
                
                # ç«‹å³å›è°ƒï¼ˆå…³é”®ï¼è¾¹å½•è¾¹å‘ï¼‰
                if frame_callback:
                    frame_callback(data)
                
                # å¦‚æœéœ€è¦ä¿å­˜æ–‡ä»¶
                if output_file:
                    frames.append(data)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + 1) / total_frames * 100
                print(f"\rğŸ”´ å½•éŸ³ä¸­... {progress:.0f}%", end='', flush=True)
            
            print("\nâœ… å½•éŸ³å®Œæˆï¼")
            
            # åœæ­¢å½•éŸ³
            stream.stop_stream()
            stream.close()
            
            # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if output_file and frames:
                output_dir = os.path.dirname(output_file)
                if output_dir and not os.path.exists(output_dir):
                    os.makedirs(output_dir, exist_ok=True)
                
                if output_file.endswith('.pcm'):
                    # ä¿å­˜ä¸ºPCMæ ¼å¼
                    with open(output_file, 'wb') as f:
                        f.write(b''.join(frames))
                elif output_file.endswith('.wav'):
                    # ä¿å­˜ä¸ºWAVæ ¼å¼
                    with wave.open(output_file, 'wb') as wf:
                        wf.setnchannels(self.channels)
                        wf.setsampwidth(audio.get_sample_size(self.format))
                        wf.setframerate(actual_sample_rate)
                        wf.writeframes(b''.join(frames))
                
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜åˆ°ï¼š{output_file}")
                return output_file
            
            return None
            
        except Exception as e:
            print(f"\nâŒ å½•éŸ³å¤±è´¥: {e}")
            raise
        finally:
            self.is_recording = False
            audio.terminate()
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        self.is_recording = False

    def record_with_vad(self,
                        max_duration=30,
                        output_file=None,
                        vad_threshold=0.5,
                        min_speech_duration_ms=250,
                        min_silence_duration_ms=800):
        """
        ä½¿ç”¨VADè‡ªåŠ¨æ£€æµ‹çš„å½•éŸ³æ–¹æ³•

        :param max_duration: æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢æ— é™å½•éŸ³
        :param output_file: ä¿å­˜æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        :param vad_threshold: VADé˜ˆå€¼
        :param min_speech_duration_ms: æœ€å°è¯­éŸ³æ—¶é•¿
        :param min_silence_duration_ms: æœ€å°é™éŸ³æ—¶é•¿ï¼ˆè¯´å®Œå¤šä¹…ç®—ç»“æŸï¼‰
        :return: (å½•éŸ³æ•°æ®, å®é™…å½•éŸ³æ—¶é•¿)
        """
        from vad_detector import VADDetector

        print(f"ğŸ¤ å¼€å§‹VADæ™ºèƒ½å½•éŸ³ï¼ˆæœ€é•¿{max_duration}ç§’ï¼‰...")
        print(f"ğŸ’¡ æç¤ºï¼šæ£€æµ‹åˆ°é™éŸ³{min_silence_duration_ms}msåè‡ªåŠ¨åœæ­¢")

        # åˆ›å»ºVADæ£€æµ‹å™¨
        vad = VADDetector(
            sample_rate=self.sample_rate,
            threshold=vad_threshold,
            min_speech_duration_ms=min_speech_duration_ms,
            min_silence_duration_ms=min_silence_duration_ms,
            window_size_samples=self.chunk
        )

        # åˆå§‹åŒ– PyAudio
        audio = pyaudio.PyAudio()
        
        try:
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                input_device_index=self.input_device_index,
                frames_per_buffer=self.chunk
            )

            print("ğŸ™ï¸ éº¦å…‹é£å·²å°±ç»ªï¼Œè¯·å¼€å§‹è¯´è¯...")

            frames = []
            start_time = time.time()
            frame_count = 0
            speech_detected = False

            try:
                while True:
                    # è¯»å–éŸ³é¢‘å¸§
                    data = stream.read(self.chunk, exception_on_overflow=False)
                    frame_count += 1

                    # VADæ£€æµ‹
                    is_speech, should_stop = vad.process_frame(data)

                    # çŠ¶æ€æ˜¾ç¤º
                    if is_speech and not speech_detected:
                        print("ğŸ—£ï¸ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³...")
                        speech_detected = True

                    # ä¿å­˜éŸ³é¢‘å¸§
                    if speech_detected:
                        frames.append(data)

                    # å®æ—¶æ˜¾ç¤º
                    if frame_count % 10 == 0:  # æ¯10å¸§æ›´æ–°ä¸€æ¬¡
                        elapsed = time.time() - start_time
                        status = "ğŸ—£ï¸ è¯­éŸ³" if is_speech else "ğŸ¤« é™éŸ³"
                        print(f"\râ±ï¸ {elapsed:.1f}s | {status} | å¸§æ•°: {len(frames)}",
                              end='', flush=True)

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                    if should_stop:
                        print("\nâœ… æ£€æµ‹åˆ°è¯´è¯ç»“æŸï¼Œåœæ­¢å½•éŸ³")
                        break

                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                    if time.time() - start_time > max_duration:
                        print(f"\nâ° è¾¾åˆ°æœ€å¤§æ—¶é•¿ {max_duration}ç§’ï¼Œåœæ­¢å½•éŸ³")
                        break

            except KeyboardInterrupt:
                print("\nâš ï¸ å½•éŸ³è¢«ä¸­æ–­")
            finally:
                stream.stop_stream()
                stream.close()

            # è®¡ç®—å®é™…å½•éŸ³æ—¶é•¿
            actual_duration = len(frames) * self.chunk / self.sample_rate
            print(f"ğŸ“Š å®é™…å½•éŸ³æ—¶é•¿: {actual_duration:.2f}ç§’")

            if not frames:
                print("âŒ æœªå½•åˆ¶åˆ°ä»»ä½•éŸ³é¢‘")
                return None, 0

            # åˆå¹¶éŸ³é¢‘æ•°æ®
            audio_data = b''.join(frames)

            # ä¿å­˜æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            if output_file:
                self._save_wav(audio_data, output_file, audio)
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_file}")

            return audio_data, actual_duration
        
        finally:
            audio.terminate()

    def record_with_vad_lite(self,
                             max_duration=30,
                             output_file=None,
                             aggressiveness=2,
                             min_silence_duration_ms=800):
        """
        ä½¿ç”¨è½»é‡çº§ VAD è‡ªåŠ¨æ£€æµ‹çš„å½•éŸ³æ–¹æ³•ï¼ˆé€‚åˆæ ‘è“æ´¾ Zero 2Wï¼‰

        :param max_duration: æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
        :param output_file: ä¿å­˜æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        :param aggressiveness: VAD æ•æ„Ÿåº¦ 0-3ï¼ˆæ¨è2ï¼‰
        :param min_silence_duration_ms: æœ€å°é™éŸ³æ—¶é•¿ï¼ˆè¯´å®Œå¤šä¹…ç®—ç»“æŸï¼‰
        :return: (å½•éŸ³æ•°æ®, å®é™…å½•éŸ³æ—¶é•¿)
        """
        from vad_detector_lite import VADDetectorLite

        print(f"ğŸ¤ å¼€å§‹è½»é‡çº§VADå½•éŸ³ï¼ˆæœ€é•¿{max_duration}ç§’ï¼‰...")
        print(f"ğŸ’¡ æç¤ºï¼šæ£€æµ‹åˆ°é™éŸ³{min_silence_duration_ms}msåè‡ªåŠ¨åœæ­¢")

        # åˆ›å»ºè½»é‡çº§ VAD æ£€æµ‹å™¨
        vad = VADDetectorLite(
            sample_rate=self.sample_rate,
            aggressiveness=aggressiveness,
            frame_duration_ms=30,  # å›ºå®š30mså¸§
            padding_duration_ms=300,
            min_silence_duration_ms=min_silence_duration_ms
        )

        # WebRTC VAD éœ€è¦ç‰¹å®šçš„å¸§å¤§å°
        vad_chunk_size = vad.get_frame_size_bytes()
        vad_chunk_samples = vad_chunk_size // 2  # int16 = 2å­—èŠ‚

        print(f"ğŸ”§ VADå¸§å¤§å°: {vad_chunk_samples} æ ·æœ¬ ({vad_chunk_size} å­—èŠ‚)")

        # åˆå§‹åŒ– PyAudio
        audio = pyaudio.PyAudio()
        
        try:
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                input_device_index=self.input_device_index,
                frames_per_buffer=vad_chunk_samples  # ä½¿ç”¨VADè¦æ±‚çš„å¸§å¤§å°
            )

            print("ğŸ™ï¸  éº¦å…‹é£å·²å°±ç»ªï¼Œè¯·å¼€å§‹è¯´è¯...")

            frames = []
            start_time = time.time()
            frame_count = 0
            speech_detected = False

            try:
                while True:
                    # è¯»å–éŸ³é¢‘å¸§ï¼ˆå¤§å°åŒ¹é…VADè¦æ±‚ï¼‰
                    data = stream.read(vad_chunk_samples, exception_on_overflow=False)
                    frame_count += 1

                    # VAD æ£€æµ‹
                    is_speech, should_stop, buffered_audio = vad.process_frame(data)

                    # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°è¯­éŸ³
                    if vad.is_speaking and not speech_detected:
                        speech_detected = True

                    # å®æ—¶æ˜¾ç¤º
                    if frame_count % 10 == 0:
                        elapsed = time.time() - start_time
                        status = "ğŸ—£ï¸  è¯­éŸ³" if is_speech else "ğŸ¤« é™éŸ³"
                        silence = vad.silence_counter if vad.triggered else 0
                        print(f"\râ±ï¸  {elapsed:.1f}s | {status} | é™éŸ³è®¡æ•°: {silence}/{vad.silence_frames}",
                              end='', flush=True)

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                    if should_stop:
                        print("\nâœ… æ£€æµ‹åˆ°è¯´è¯ç»“æŸï¼Œåœæ­¢å½•éŸ³")
                        if buffered_audio:
                            frames = [buffered_audio]
                        break

                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                    if time.time() - start_time > max_duration:
                        print(f"\nâ° è¾¾åˆ°æœ€å¤§æ—¶é•¿ {max_duration}ç§’ï¼Œåœæ­¢å½•éŸ³")
                        # è·å–ç¼“å†²çš„éŸ³é¢‘
                        if vad.voiced_frames:
                            frames = [b''.join(vad.voiced_frames)]
                        break

            except KeyboardInterrupt:
                print("\nâš ï¸  å½•éŸ³è¢«ä¸­æ–­")
            finally:
                stream.stop_stream()
                stream.close()

            if not frames:
                print("âŒ æœªå½•åˆ¶åˆ°ä»»ä½•éŸ³é¢‘")
                return None, 0

            # åˆå¹¶éŸ³é¢‘æ•°æ®
            audio_data = frames[0] if len(frames) == 1 else b''.join(frames)

            # è®¡ç®—å®é™…å½•éŸ³æ—¶é•¿
            actual_duration = len(audio_data) / (self.sample_rate * 2)  # 2å­—èŠ‚peræ ·æœ¬
            print(f"ğŸ“Š å®é™…å½•éŸ³æ—¶é•¿: {actual_duration:.2f}ç§’")

            # ä¿å­˜æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            if output_file:
                self._save_wav(audio_data, output_file, audio)
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_file}")

            return audio_data, actual_duration
        
        finally:
            audio.terminate()
    
    def _save_wav(self, audio_data, output_file, audio):
        """
        ä¿å­˜éŸ³é¢‘æ•°æ®ä¸ºWAVæ–‡ä»¶
        
        :param audio_data: éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
        :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        :param audio: PyAudioå®ä¾‹
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åä¿å­˜
        if output_file.endswith('.pcm'):
            # ä¿å­˜ä¸ºPCMæ ¼å¼
            with open(output_file, 'wb') as f:
                f.write(audio_data)
        elif output_file.endswith('.wav'):
            # ä¿å­˜ä¸ºWAVæ ¼å¼
            with wave.open(output_file, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(audio.get_sample_size(self.format))
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_data)
        else:
            # é»˜è®¤ä¿å­˜ä¸ºWAV
            with wave.open(output_file + '.wav', 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(audio.get_sample_size(self.format))
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_data)


class AudioPlayer:
    """éŸ³é¢‘æ’­æ”¾ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ’­æ”¾å™¨"""
        pygame.mixer.init()
        
    def play(self, audio_file, wait=True):
        """
        æ’­æ”¾éŸ³é¢‘æ–‡ä»¶
        :param audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param wait: æ˜¯å¦ç­‰å¾…æ’­æ”¾å®Œæˆ
        """
        if not os.path.exists(audio_file):
            print(f" æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_file}")
            return
        
        print(f" æ’­æ”¾éŸ³é¢‘ï¼š{audio_file}")
        
        try:
            pygame.mixer.music.load(audio_file)
            pygame.mixer.music.play()
            
            if wait:
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    pygame.time.Clock().tick(10)
                print(" æ’­æ”¾å®Œæˆï¼")
        except Exception as e:
            print(f" æ’­æ”¾å¤±è´¥ï¼š{e}")
    
    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        pygame.mixer.music.stop()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•å½•éŸ³
    recorder = AudioRecorder()
    audio_file = "./audio_files/test_record.pcm"
    recorder.record(duration=3, output_file=audio_file)
    
    # æµ‹è¯•æ’­æ”¾ï¼ˆéœ€è¦å…ˆæœ‰mp3æ–‡ä»¶ï¼‰
    # player = AudioPlayer()
    # player.play("./audio_files/test.mp3")

