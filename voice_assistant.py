# -*- coding:utf-8 -*-
"""
æ ‘è“æ´¾è¯­éŸ³åŠ©æ‰‹ä¸»ç¨‹åº
æ•´åˆå½•éŸ³ã€è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆå’Œæ’­æ”¾åŠŸèƒ½
"""

import os
import sys
import time
import pyaudio
from config import (
    XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET,
    OUTPUT_DIR, RECORDED_AUDIO, TTS_AUDIO,
    AUDIO_CONFIG, TTS_CONFIG, VAD_CONFIG, WAKE_RESPONSE_CONFIG,
    PORCUPINE_ACCESS_KEY, PORCUPINE_USE_CUSTOM,
    PORCUPINE_CUSTOM_MODEL_PATH, PORCUPINE_CUSTOM_KEYWORD,
    PORCUPINE_LANGUAGE_MODEL_PATH, PORCUPINE_SENSITIVITY,
    PORCUPINE_BUILTIN_KEYWORDS
)
from xfyun_asr_manual import XFyunASRManual
from xfyun_asr_stream import XFyunASRStream  # æµå¼ASR
from xfyun_tts_manual import XFyunTTSManual
from xfyun_tts_stream import XFyunTTSStream  # æµå¼TTS
from audio_utils import AudioRecorder, AudioPlayer


def setup_alsa_environment():
    """
    è®¾ç½®ALSAç¯å¢ƒ
    """
    print(" é…ç½®éŸ³é¢‘ç¯å¢ƒ...")
    
    # åˆ é™¤å¯èƒ½æœ‰é—®é¢˜çš„ALSAé…ç½®æ–‡ä»¶
    config_path = os.path.expanduser("~/.asoundrc")
    if os.path.exists(config_path):
        try:
            os.remove(config_path)
            print("   å·²åˆ é™¤æ—§çš„ALSAé…ç½®")
        except:
            pass
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå…³é”®ï¼ï¼‰
    os.environ['AUDIODEV'] = 'plughw:1,0'
    os.environ['ALSA_CARD'] = '1'
    print("   å·²è®¾ç½®éŸ³é¢‘ç¯å¢ƒå˜é‡")


class VoiceAssistant:
    """è¯­éŸ³åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹"""
        print("=" * 60)
        print(" æ ‘è“æ´¾è¯­éŸ³åŠ©æ‰‹åˆå§‹åŒ–ä¸­...")
        print("=" * 60)
        
        # é¦–å…ˆè®¾ç½®éŸ³é¢‘ç¯å¢ƒï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
        setup_alsa_environment()
        
        # æ£€æŸ¥é…ç½®
        if not self._check_config():
            print(" é…ç½®æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆåœ¨ config.py ä¸­å¡«å†™è®¯é£APIå‡­è¯ï¼")
            sys.exit(1)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(OUTPUT_DIR):
            os.makedirs(OUTPUT_DIR)
            print(f" åˆ›å»ºè¾“å‡ºç›®å½•ï¼š{OUTPUT_DIR}")
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—ï¼ˆä¿®å¤ï¼šä½¿ç”¨æ‰‹åŠ¨å®ç°ï¼‰
        self.asr = XFyunASRManual(XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET)
        self.asr_stream = XFyunASRStream(XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET)  # æµå¼ASR
        self.tts = XFyunTTSManual(XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET)
        self.tts_stream = XFyunTTSStream(XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET)  # æµå¼TTS
        self.recorder = AudioRecorder(
            sample_rate=AUDIO_CONFIG["sample_rate"],
            channels=AUDIO_CONFIG["channels"],
            chunk=AUDIO_CONFIG["chunk"],
            input_device_index=AUDIO_CONFIG.get("input_device_index")  # æŒ‡å®šéº¦å…‹é£
        )
        self.player = AudioPlayer()
        
        # é»˜è®¤ä½¿ç”¨æµå¼æ¨¡å¼ï¼ˆæ›´ä½å»¶è¿Ÿï¼‰
        self.use_stream_asr = True  # æµå¼è¯†åˆ«
        self.use_stream_tts = True  # æµå¼æ’­æ”¾
        
        # åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹å™¨
        self.wake_word_detector = None
        self._init_wake_word_detector()
        
        print(" è¯­éŸ³åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
    
    def _init_wake_word_detector(self):
        """åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹å™¨"""
        if not PORCUPINE_ACCESS_KEY or PORCUPINE_ACCESS_KEY == "ä½ çš„AccessKey":
            print("âš ï¸  æœªé…ç½®Porcupine Access Keyï¼Œå”¤é†’åŠŸèƒ½æœªå¯ç”¨")
            print("   è¯·åœ¨ config.py ä¸­é…ç½® PORCUPINE_ACCESS_KEY")
            return False
        
        try:
            if PORCUPINE_USE_CUSTOM:
                # ä½¿ç”¨è‡ªå®šä¹‰ä¸­æ–‡å”¤é†’è¯
                from wake_word_detector_porcupine_custom import PorcupineCustomDetector
                
                if not os.path.exists(PORCUPINE_CUSTOM_MODEL_PATH):
                    print(f"âš ï¸  è‡ªå®šä¹‰æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {PORCUPINE_CUSTOM_MODEL_PATH}")
                    return False
                
                self.wake_word_detector = PorcupineCustomDetector(
                    access_key=PORCUPINE_ACCESS_KEY,
                    keyword_paths=[PORCUPINE_CUSTOM_MODEL_PATH],
                    keywords=[PORCUPINE_CUSTOM_KEYWORD],
                    sensitivities=[PORCUPINE_SENSITIVITY],
                    model_path=PORCUPINE_LANGUAGE_MODEL_PATH
                )
                print(f"ğŸ¯ ä½¿ç”¨è‡ªå®šä¹‰å”¤é†’è¯: {PORCUPINE_CUSTOM_KEYWORD}")
            else:
                # ä½¿ç”¨å†…ç½®è‹±æ–‡å”¤é†’è¯
                from wake_word_detector_porcupine import PorcupineDetector
                
                self.wake_word_detector = PorcupineDetector(
                    access_key=PORCUPINE_ACCESS_KEY,
                    keywords=PORCUPINE_BUILTIN_KEYWORDS,
                    sensitivities=[PORCUPINE_SENSITIVITY] * len(PORCUPINE_BUILTIN_KEYWORDS)
                )
                print(f"ğŸ¯ ä½¿ç”¨å†…ç½®å”¤é†’è¯: {', '.join(PORCUPINE_BUILTIN_KEYWORDS)}")
            
            if self.wake_word_detector.initialize():
                print("âœ… å”¤é†’è¯æ£€æµ‹å™¨å·²å¯ç”¨")
                return True
            else:
                print("âŒ å”¤é†’è¯æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
                self.wake_word_detector = None
                return False
                
        except Exception as e:
            print(f"âŒ å”¤é†’è¯æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
            self.wake_word_detector = None
            return False
    
    def _check_config(self):
        """æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´"""
        if (XFYUN_APPID == "your_appid_here" or 
            XFYUN_API_KEY == "your_api_key_here" or 
            XFYUN_API_SECRET == "your_api_secret_here"):
            return False
        return True

    def listen(self, duration=5, use_stream=None, use_vad=False):
        """
        ç›‘å¬ç”¨æˆ·è¯­éŸ³è¾“å…¥
        :param duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒVADæ¨¡å¼ä¸‹ä½œä¸ºæœ€å¤§æ—¶é•¿
        :param use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¯†åˆ«ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
        :param use_vad: æ˜¯å¦ä½¿ç”¨VADè‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼ï¼‰
        :return: è¯†åˆ«çš„æ–‡æœ¬
        """
        print("\n" + "=" * 60)
        print("ğŸ‘‚ å¼€å§‹ç›‘å¬...")
        if use_vad:
            print("ğŸ§  è½»é‡çº§VADæ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹è¯´è¯ç»“æŸï¼ˆé€‚é…Zero 2Wï¼‰")
        print("=" * 60)

        # ç¡®å®šä½¿ç”¨æµå¼è¿˜æ˜¯éæµå¼
        if use_stream is None:
            use_stream = self.use_stream_asr

        if use_vad:
            # VADæ¨¡å¼ï¼šä½¿ç”¨è½»é‡çº§å½•éŸ³
            print("âš¡ ä½¿ç”¨è½»é‡çº§VADå½•éŸ³ï¼ˆWebRTCï¼‰")

            audio_data, actual_duration = self.recorder.record_with_vad_lite(
                max_duration=duration,
                output_file=RECORDED_AUDIO if not use_stream else None,
                aggressiveness=2,  # æ ‡å‡†æ•æ„Ÿåº¦
                min_silence_duration_ms=800
            )

            if not audio_data:
                print("\nâš ï¸  æœªå½•åˆ¶åˆ°éŸ³é¢‘")
                return ""

            if use_stream:
                # æµå¼è¯†åˆ«ï¼šå¯åŠ¨ASR
                self.asr_stream.start_recognition()

                # åˆ†å¸§å‘é€éŸ³é¢‘
                chunk_size = self.recorder.chunk * 2  # å­—èŠ‚æ•°
                for i in range(0, len(audio_data), chunk_size):
                    frame = audio_data[i:i + chunk_size]
                    self.asr_stream.add_audio_frame(frame)

                # ç»“æŸè¯†åˆ«
                self.asr_stream.finish_recording()
                text = self.asr_stream.wait_result(timeout=10)
            else:
                # ä¼ ç»Ÿè¯†åˆ«
                text = self.asr.recognize_file(RECORDED_AUDIO)

        else:
            # éVADæ¨¡å¼ï¼ˆå›ºå®šæ—¶é•¿ï¼‰
            if use_stream:
                print("âš¡ ä½¿ç”¨æµå¼è¯†åˆ«æ¨¡å¼ï¼ˆé›¶å»¶è¿Ÿï¼‰")
                self.asr_stream.start_recognition()

                self.recorder.record_stream(
                    duration=duration,
                    frame_callback=self.asr_stream.add_audio_frame,
                    output_file=None
                )

                self.asr_stream.finish_recording()
                text = self.asr_stream.wait_result(timeout=10)
            else:
                print("ğŸ’¾ ä½¿ç”¨ä¼ ç»Ÿè¯†åˆ«æ¨¡å¼")
                audio_file = self.recorder.record(duration, RECORDED_AUDIO)
                text = self.asr.recognize_file(audio_file)

        if text:
            print(f"\nâœ… è¯†åˆ«ç»“æœï¼š{text}")
            return text
        else:
            print("\nâš ï¸  æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")
            return ""
    
    def speak(self, text, use_stream=None):
        """
        è¯­éŸ³æ’­æŠ¥
        :param text: è¦æ’­æŠ¥çš„æ–‡æœ¬
        :param use_stream: æ˜¯å¦ä½¿ç”¨æµå¼æ’­æ”¾ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
        """
        print("\n" + "=" * 60)
        print(f"ğŸ”Š å‡†å¤‡æ’­æŠ¥ï¼š{text}")
        print("=" * 60)

        # ç¡®å®šä½¿ç”¨æµå¼è¿˜æ˜¯éæµå¼
        if use_stream is None:
            use_stream = self.use_stream_tts
        
        if use_stream:
            # æµå¼æ’­æ”¾ï¼ˆæ¨èï¼Œå»¶è¿Ÿæ›´ä½ï¼‰
            print("âš¡ ä½¿ç”¨æµå¼æ’­æ”¾æ¨¡å¼ï¼ˆä½å»¶è¿Ÿï¼‰")
            self.tts_stream.synthesize_and_play(
                text=text,
                vcn=TTS_CONFIG["vcn"],
                speed=TTS_CONFIG["speed"],
                volume=TTS_CONFIG["volume"],
                pitch=TTS_CONFIG["pitch"],
                save_file=None  # ä¸ä¿å­˜æ–‡ä»¶ï¼Œç›´æ¥æ’­æ”¾
            )
        else:
            # ä¼ ç»Ÿæ–¹å¼ï¼ˆå®Œæ•´æ–‡ä»¶æ’­æ”¾ï¼‰
            print("ğŸ’¾ ä½¿ç”¨ä¼ ç»Ÿæ’­æ”¾æ¨¡å¼ï¼ˆä¿å­˜æ–‡ä»¶ï¼‰")
            audio_file = self.tts.synthesize(
                text=text,
                output_file=TTS_AUDIO,
                vcn=TTS_CONFIG["vcn"],
                speed=TTS_CONFIG["speed"],
                volume=TTS_CONFIG["volume"],
                pitch=TTS_CONFIG["pitch"]
            )

            # æ’­æ”¾éŸ³é¢‘
            if audio_file and os.path.exists(audio_file):
                print("\n" + "-" * 60)
                self.player.play(audio_file, wait=True)
                print("-" * 60)
            else:
                print("âŒ è¯­éŸ³åˆæˆå¤±è´¥ï¼Œæ— æ³•æ’­æ”¾")
    
    def test_mode(self):
        """æµ‹è¯•æ¨¡å¼ï¼šæµ‹è¯•æ‰€æœ‰åŠŸèƒ½"""
        print("\n è¿›å…¥æµ‹è¯•æ¨¡å¼")
        print("=" * 60)
        
        # æµ‹è¯•1ï¼šTTSè¯­éŸ³æ’­æŠ¥
        print("\nã€æµ‹è¯•1ã€‘è¯­éŸ³åˆæˆä¸æ’­æ”¾")
        test_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„æ ‘è“æ´¾è¯­éŸ³åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚"
        self.speak(test_text)
        
        # æµ‹è¯•2ï¼šå½•éŸ³å’Œè¯­éŸ³è¯†åˆ«
        print("\nã€æµ‹è¯•2ã€‘å½•éŸ³ä¸è¯­éŸ³è¯†åˆ«")
        print(" è¯·åœ¨æ¥ä¸‹æ¥çš„5ç§’å†…è¯´è¯...")
        input("æŒ‰å›è½¦é”®å¼€å§‹å½•éŸ³...")
        user_text = self.listen(duration=5)
        
        # æµ‹è¯•3ï¼šå¯¹è¯å›å¤
        if user_text:
            print("\nã€æµ‹è¯•3ã€‘è¯­éŸ³å›å¤")
            response = f"æˆ‘å¬åˆ°ä½ è¯´ï¼š{user_text}"
            self.speak(response)
        
        print("\n æµ‹è¯•å®Œæˆï¼")

    def interactive_mode(self):
        """äº¤äº’æ¨¡å¼ï¼šæŒç»­å¯¹è¯"""
        print("\nğŸ™ï¸ è¿›å…¥äº¤äº’æ¨¡å¼")
        print("=" * 60)
        print("æç¤ºï¼š")
        print("  - æŒ‰å›è½¦é”®å¼€å§‹å½•éŸ³ï¼ˆVADæ™ºèƒ½æ£€æµ‹ç»“æŸï¼‰")
        print("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("  - è¾“å…¥ 'speak:æ–‡æœ¬' ç›´æ¥æ’­æŠ¥æ–‡æœ¬")
        print("  - è¾“å…¥ 'vad' åˆ‡æ¢VADå¼€å…³")
        print(f"  - VADçŠ¶æ€ï¼š{'âœ… å¼€å¯ï¼ˆæ™ºèƒ½æ£€æµ‹ï¼‰' if self.use_vad else 'âŒ å…³é—­ï¼ˆå›ºå®š5ç§’ï¼‰'}")
        print("=" * 60)

        # æ·»åŠ VADå¼€å…³
        self.use_vad = True  # é»˜è®¤å¼€å¯VAD

        while True:
            try:
                # ç­‰å¾…ç”¨æˆ·æŒ‡ä»¤
                user_input = input("\nğŸ¤ è¯·è¾“å…¥æŒ‡ä»¤ï¼ˆç›´æ¥å›è½¦å¼€å§‹å½•éŸ³ï¼‰ï¼š").strip()

                # é€€å‡º
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break

                # åˆ‡æ¢VAD
                elif user_input.lower() == 'vad':
                    self.use_vad = not self.use_vad
                    status = 'âœ… å¼€å¯ï¼ˆæ™ºèƒ½æ£€æµ‹ï¼‰' if self.use_vad else 'âŒ å…³é—­ï¼ˆå›ºå®š5ç§’ï¼‰'
                    print(f"ğŸ’¡ VADå·²åˆ‡æ¢: {status}")
                    continue

                # ç›´æ¥æ’­æŠ¥
                elif user_input.startswith('speak:') or user_input.startswith('è¯´:'):
                    text = user_input.split(':', 1)[1].strip()
                    if text:
                        self.speak(text)
                    else:
                        print("âš ï¸ è¯·è¾“å…¥è¦æ’­æŠ¥çš„æ–‡æœ¬")

                # å½•éŸ³è¯†åˆ«ï¼ˆä½¿ç”¨VADï¼‰
                else:
                    user_text = self.listen(duration=30, use_vad=self.use_vad)

                    if user_text:
                        # è¿™é‡Œåç»­å¯ä»¥æ¥å…¥å¤§æ¨¡å‹
                        # ç›®å‰åªåšç®€å•å›å¤
                        response = f"æ”¶åˆ°ï¼Œä½ è¯´çš„æ˜¯ï¼š{user_text}"
                        self.speak(response)

            except KeyboardInterrupt:
                print("\n\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯ï¼š{e}")
                continue
    
    def run_with_wake_word(self):
        """å”¤é†’è¯æ¨¡å¼ï¼šç­‰å¾…å”¤é†’ â†’ æ’­æ”¾å›åº” â†’ VADå½•éŸ³ â†’ ASRè¯†åˆ« â†’ å›å¤ â†’ å¾ªç¯"""
        if not self.wake_word_detector:
            print("âŒ å”¤é†’è¯æ£€æµ‹å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨å”¤é†’æ¨¡å¼")
            print("   è¯·æ£€æŸ¥ config.py ä¸­çš„ PORCUPINE_ACCESS_KEY é…ç½®")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ¤ è¯­éŸ³åŠ©æ‰‹ - å”¤é†’è¯æ¨¡å¼")
        print("=" * 60)
        
        if PORCUPINE_USE_CUSTOM:
            print(f"ğŸ¯ å”¤é†’è¯: {PORCUPINE_CUSTOM_KEYWORD}")
        else:
            print(f"ğŸ¯ å”¤é†’è¯: {', '.join(PORCUPINE_BUILTIN_KEYWORDS)}")
        
        print(f"ğŸšï¸  æ•æ„Ÿåº¦: {PORCUPINE_SENSITIVITY}")
        print(f"ğŸ’¬ å›åº”è¯­: ä½ å¥½ï¼Œæ˜")
        print(f"â±ï¸  ç›‘å¬è¶…æ—¶: {WAKE_RESPONSE_CONFIG['listen_timeout']}ç§’")
        print("=" * 60)
        print("ğŸ’¡ è¯´å‡ºå”¤é†’è¯æ¥æ¿€æ´»åŠ©æ‰‹ï¼ˆæŒ‰Ctrl+Cé€€å‡ºï¼‰")
        print("=" * 60)
        
        # åˆå§‹åŒ–PyAudio
        audio = pyaudio.PyAudio()
        
        try:
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.wake_word_detector.get_sample_rate(),
                input=True,
                input_device_index=AUDIO_CONFIG.get('input_device_index'),
                frames_per_buffer=self.wake_word_detector.get_frame_length()
            )
            
            print("ğŸ™ï¸  ç›‘å¬å”¤é†’è¯ä¸­...\n")
            
            wake_count = 0
            
            while True:
                # è¯»å–éŸ³é¢‘å¸§
                pcm_data = stream.read(self.wake_word_detector.get_frame_length(), exception_on_overflow=False)
                
                # æ£€æµ‹å”¤é†’è¯
                detected, keyword_index = self.wake_word_detector.detect(pcm_data)
                
                if detected and keyword_index >= 0:
                    wake_count += 1
                    keyword = PORCUPINE_CUSTOM_KEYWORD if PORCUPINE_USE_CUSTOM else PORCUPINE_BUILTIN_KEYWORDS[keyword_index]
                    
                    print(f"\nâœ¨ æ£€æµ‹åˆ°å”¤é†’è¯: {keyword}")
                    print(f"ğŸ”” è¿™æ˜¯ç¬¬ {wake_count} æ¬¡å”¤é†’\n")
                    
                    # æ’­æ”¾å›åº”è¯­éŸ³ï¼š"ä½ å¥½ï¼Œæ˜"ï¼ˆæœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼‰
                    response_audio = WAKE_RESPONSE_CONFIG.get('response_audio')
                    if response_audio and os.path.exists(response_audio):
                        print("ğŸ”Š æ’­æ”¾å›åº”: ä½ å¥½ï¼Œæ˜")
                        try:
                            self.player.play(response_audio, wait=True)
                        except Exception as e:
                            print(f"âš ï¸  æ’­æ”¾å›åº”å¤±è´¥: {e}")
                    else:
                        print(f"âš ï¸  å›åº”éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {response_audio}")
                        print("   è¯·å°† 'ä½ å¥½æ˜.wav' æ”¾ç½®åˆ° ./audio_files/ ç›®å½•")
                    
                    # æš‚åœå”¤é†’æ£€æµ‹æµï¼ˆé¿å…å½•åˆ¶æ—¶æ£€æµ‹åˆ°è‡ªå·±çš„å£°éŸ³ï¼‰
                    stream.stop_stream()
                    
                    # ä½¿ç”¨VADå½•åˆ¶ç”¨æˆ·è¯­éŸ³
                    print("\nğŸ“ è¯·è¯´è¯...")
                    try:
                        audio_data, duration = self.recorder.record_with_vad_lite(
                            max_duration=WAKE_RESPONSE_CONFIG['listen_timeout'],
                            aggressiveness=VAD_CONFIG['aggressiveness'],
                            min_silence_duration_ms=VAD_CONFIG['min_silence_duration_ms']
                        )
                        
                        if audio_data is None or len(audio_data) == 0:
                            print("âš ï¸  æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥")
                            # é‡æ–°å¼€å§‹ç›‘å¬å”¤é†’è¯
                            stream.start_stream()
                            print("\nğŸ™ï¸  ç›‘å¬å”¤é†’è¯ä¸­...\n")
                            continue
                        
                        print(f"âœ… å½•éŸ³å®Œæˆï¼ˆæ—¶é•¿: {duration:.1f}ç§’ï¼‰")
                        
                        # ASRè¯†åˆ«
                        print("ğŸ”„ è¯†åˆ«ä¸­...")
                        if self.use_stream_asr:
                            # æµå¼è¯†åˆ«ï¼šå¯åŠ¨ASR
                            self.asr_stream.start_recognition()
                            
                            # åˆ†å¸§å‘é€éŸ³é¢‘
                            chunk_size = self.recorder.chunk * 2  # å­—èŠ‚æ•°
                            for i in range(0, len(audio_data), chunk_size):
                                frame = audio_data[i:i + chunk_size]
                                self.asr_stream.add_audio_frame(frame)
                            
                            # ç»“æŸè¯†åˆ«
                            self.asr_stream.finish_recording()
                            user_text = self.asr_stream.wait_result(timeout=10)
                        else:
                            # æ‰‹åŠ¨è¯†åˆ«
                            user_text = self.asr.recognize(audio_data)
                        
                        if not user_text:
                            print("âŒ è¯†åˆ«å¤±è´¥æˆ–æœªè¯†åˆ«åˆ°å†…å®¹")
                            # é‡æ–°å¼€å§‹ç›‘å¬å”¤é†’è¯
                            stream.start_stream()
                            print("\nğŸ™ï¸  ç›‘å¬å”¤é†’è¯ä¸­...\n")
                            continue
                        
                        print(f"ğŸ’¬ ç”¨æˆ·: {user_text}")
                        
                        # ç®€å•å›å¤ï¼ˆåç»­å¯æ¥LLMï¼‰
                        reply = self._generate_simple_reply(user_text)
                        print(f"ğŸ¤– åŠ©æ‰‹: {reply}")
                        
                        # TTSæ’­æ”¾å›å¤
                        self.speak(reply)
                        
                        # ç»§ç»­ç›‘å¬å”¤é†’è¯
                        if WAKE_RESPONSE_CONFIG.get('return_to_wake_mode', True):
                            stream.start_stream()
                            print("\nğŸ™ï¸  ç›‘å¬å”¤é†’è¯ä¸­...\n")
                        else:
                            print("âœ… å¯¹è¯ç»“æŸ")
                            break
                    
                    except Exception as e:
                        print(f"âŒ å¤„ç†ç”¨æˆ·è¯­éŸ³æ—¶å‡ºé”™: {e}")
                        # é‡æ–°å¼€å§‹ç›‘å¬å”¤é†’è¯
                        stream.start_stream()
                        print("\nğŸ™ï¸  ç›‘å¬å”¤é†’è¯ä¸­...\n")
                        continue
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        
        except Exception as e:
            print(f"\nâŒ å”¤é†’æ¨¡å¼è¿è¡Œå‡ºé”™: {e}")
        
        finally:
            # æ¸…ç†èµ„æº
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass
            
            audio.terminate()
            
            if self.wake_word_detector:
                self.wake_word_detector.cleanup()
            
            print(f"\nâœ… å”¤é†’æ¨¡å¼ç»“æŸï¼ˆæ€»å…±å”¤é†’ {wake_count} æ¬¡ï¼‰")
    
    def _generate_simple_reply(self, user_text):
        """
        ç”Ÿæˆç®€å•å›å¤ï¼ˆåç»­å¯æ¥å…¥LLMï¼‰
        :param user_text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        :return: å›å¤æ–‡æœ¬
        """
        user_text_lower = user_text.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if "å¤©æ°”" in user_text:
            return "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥"
        elif "æ—¶é—´" in user_text or "å‡ ç‚¹" in user_text:
            import datetime
            now = datetime.datetime.now()
            return f"ç°åœ¨æ˜¯{now.hour}ç‚¹{now.minute}åˆ†"
        elif "ä½ å¥½" in user_text or "hello" in user_text_lower:
            return "ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
        elif "å†è§" in user_text or "æ‹œæ‹œ" in user_text:
            return "å†è§ï¼ŒæœŸå¾…ä¸‹æ¬¡ä¸ä½ èŠå¤©"
        elif "è°¢è°¢" in user_text:
            return "ä¸å®¢æ°”ï¼Œå¾ˆé«˜å…´èƒ½å¸®åˆ°ä½ "
        else:
            return f"æˆ‘å¬åˆ°ä½ è¯´ï¼š{user_text}ã€‚è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å›å¤ï¼Œåç»­å¯ä»¥æ¥å…¥å¤§è¯­è¨€æ¨¡å‹"
    
    def simple_test(self):
        """ç®€å•æµ‹è¯•ï¼šå•ç‹¬æµ‹è¯•TTSæˆ–ASR"""
        print("\n ç®€å•æµ‹è¯•æ¨¡å¼")
        print("=" * 60)
        print("1. æµ‹è¯•è¯­éŸ³åˆæˆï¼ˆTTSï¼‰")
        print("2. æµ‹è¯•è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰")
        print("3. æµ‹è¯•å®Œæ•´æµç¨‹")
        print("=" * 60)
        
        choice = input("è¯·é€‰æ‹©æµ‹è¯•é¡¹ç›®ï¼ˆ1/2/3ï¼‰ï¼š").strip()
        
        if choice == '1':
            text = input("è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬ï¼š").strip()
            if text:
                self.speak(text)
            else:
                print("  æœªè¾“å…¥æ–‡æœ¬")
        
        elif choice == '2':
            print(" è¯·å‡†å¤‡ï¼Œå°†åœ¨3ç§’åå¼€å§‹å½•éŸ³...")
            import time
            time.sleep(3)
            user_text = self.listen(duration=5)
            print(f"\næœ€ç»ˆè¯†åˆ«ç»“æœï¼š{user_text}")
        
        elif choice == '3':
            self.test_mode()
        
        else:
            print("  æ— æ•ˆé€‰æ‹©")


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¯­éŸ³åŠ©æ‰‹å®ä¾‹
    assistant = VoiceAssistant()
    
    # æ˜¾ç¤ºèœå•
    print("\nğŸš€ è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ï¼š")
    print("=" * 60)
    print("1. æµ‹è¯•æ¨¡å¼ï¼ˆå®Œæ•´æµ‹è¯•æ‰€æœ‰åŠŸèƒ½ï¼‰")
    print("2. äº¤äº’æ¨¡å¼ï¼ˆæŒç»­å¯¹è¯ï¼‰")
    print("3. ç®€å•æµ‹è¯•ï¼ˆå•ç‹¬æµ‹è¯•æŸä¸ªåŠŸèƒ½ï¼‰")
    print("4. å”¤é†’è¯æ¨¡å¼ï¼ˆğŸŒŸæ¨èï¼šå”¤é†’ â†’ å¯¹è¯ â†’ å¾ªç¯ï¼‰")
    print("=" * 60)
    
    mode = input("è¯·è¾“å…¥æ¨¡å¼ç¼–å·ï¼ˆ1/2/3/4ï¼‰ï¼š").strip()
    
    if mode == '1':
        assistant.test_mode()
    elif mode == '2':
        assistant.interactive_mode()
    elif mode == '3':
        assistant.simple_test()
    elif mode == '4':
        assistant.run_with_wake_word()
    else:
        print("âŒ æ— æ•ˆçš„æ¨¡å¼é€‰æ‹©")
        print("ğŸ’¡ é»˜è®¤è¿›å…¥äº¤äº’æ¨¡å¼...")
        assistant.interactive_mode()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\n ç¨‹åºå‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()

